"""DEV.to ë°ì´í„° ìˆ˜ì§‘ê¸°"""

import os
import time
import requests
from typing import List, Optional
from dataclasses import dataclass
from datetime import datetime

import sys
sys.path.append(os.path.dirname(os.path.dirname(__file__)))
from cache import ContentCache


DEVTO_API_BASE = "https://dev.to/api"


@dataclass
class DevToArticle:
    """DEV.to ì•„í‹°í´ ë°ì´í„°"""
    id: int
    title: str
    url: str
    description: str
    tags: List[str]
    positive_reactions_count: int
    comments_count: int
    author: str
    published_at: datetime


class DevToCollector:
    """DEV.to APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„í‹°í´ì„ ìˆ˜ì§‘í•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, cache: Optional[ContentCache] = None):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "TrendReporter/1.0"
        })
        self.cache = cache

    def collect_articles(
        self,
        tag: Optional[str] = None,
        top: str = "week",
        limit: int = 30
    ) -> List[DevToArticle]:
        """ì•„í‹°í´ ìˆ˜ì§‘ (top: day, week, month, year, infinity)"""
        params = {
            "per_page": limit * 2,  # ìºì‹œ ê³ ë ¤
            "top": top
        }
        if tag:
            params["tag"] = tag

        try:
            resp = self.session.get(
                f"{DEVTO_API_BASE}/articles",
                params=params,
                timeout=15
            )
            resp.raise_for_status()
            articles_data = resp.json()
        except Exception as e:
            print(f"[DEV.to] ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

        articles = []
        for item in articles_data:
            article_id = f"devto_{item['id']}"

            # ìºì‹œëœ ì•„í‹°í´ ìŠ¤í‚µ
            if self.cache and self.cache.is_seen(article_id):
                continue

            try:
                published = datetime.fromisoformat(
                    item.get("published_at", "").replace("Z", "+00:00")
                )
            except:
                published = datetime.now()

            articles.append(DevToArticle(
                id=item["id"],
                title=item.get("title", ""),
                url=item.get("url", ""),
                description=item.get("description", ""),
                tags=item.get("tag_list", []),
                positive_reactions_count=item.get("positive_reactions_count", 0),
                comments_count=item.get("comments_count", 0),
                author=item.get("user", {}).get("username", "unknown"),
                published_at=published
            ))

            # ìºì‹œì— ì¶”ê°€
            if self.cache:
                self.cache.mark_seen(article_id)

            if len(articles) >= limit:
                break

        return articles

    def collect_all(
        self,
        general_limit: int = 20,
        tags: Optional[List[str]] = None
    ) -> dict:
        """ì¼ë°˜ + íƒœê·¸ë³„ ì•„í‹°í´ ìˆ˜ì§‘"""
        results = {
            "general": self.collect_articles(limit=general_limit)
        }

        # íƒœê·¸ë³„ ìˆ˜ì§‘ (rate limit ë°©ì§€ë¥¼ ìœ„í•´ ë”œë ˆì´ ì¶”ê°€)
        if tags:
            for tag in tags:
                time.sleep(1)  # 1ì´ˆ ë”œë ˆì´
                tag_articles = self.collect_articles(tag=tag, limit=10)
                # ì¼ë°˜ì—ì„œ ì´ë¯¸ ìˆëŠ” ê²ƒ ì œì™¸
                general_ids = {a.id for a in results["general"]}
                tag_articles = [a for a in tag_articles if a.id not in general_ids]
                if tag_articles:
                    results[tag] = tag_articles

        total = sum(len(v) for v in results.values())
        print(f"[DEV.to] ì´ {total}ê°œ ìƒˆ ì•„í‹°í´ ìˆ˜ì§‘")

        return results

    def format_for_analysis(self, data: dict) -> str:
        """ë¶„ì„ì„ ìœ„í•œ í…ìŠ¤íŠ¸ í¬ë§·"""
        output = ["\n## DEV.to\n"]

        all_articles = []
        for articles in data.values():
            all_articles.extend(articles)

        # ì¤‘ë³µ ì œê±° í›„ ë°˜ì‘ ìˆ˜ë¡œ ì •ë ¬
        seen_ids = set()
        unique_articles = []
        for a in all_articles:
            if a.id not in seen_ids:
                seen_ids.add(a.id)
                unique_articles.append(a)

        unique_articles.sort(
            key=lambda x: x.positive_reactions_count,
            reverse=True
        )

        if not unique_articles:
            return "[DEV.to] ìƒˆë¡œìš´ ì•„í‹°í´ ì—†ìŒ\n"

        for i, article in enumerate(unique_articles[:20], 1):
            tags_str = ", ".join(article.tags[:3]) if article.tags else "no tags"
            output.append(
                f"{i}. {article.title}\n"
                f"   â¤ï¸ {article.positive_reactions_count} | "
                f"ğŸ’¬ {article.comments_count} | Tags: {tags_str}\n"
                f"   URL: {article.url}\n"
            )

        return "\n".join(output)
